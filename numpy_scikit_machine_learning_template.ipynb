{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on Mac\n",
    "datadir = '/Users/kittipat/research/2015/hack2015/'\n",
    "infilename = 'hackathon2015_train_10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for hack server\n",
    "datadir = '/local/kittipat/hack15/'\n",
    "infilename = 'hackathon2015_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for seller analytics server\n",
    "datadir = '/mine/fraud/kittipat/2015/hack15/'\n",
    "infilename = 'hackathon2015_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_id = '800k_tree1500_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data to np: 3.62078595161438 sec\n",
      "data shape: (10000, 575)\n",
      "split data: 0.0980539321899414 sec\n",
      "X shape: (10000, 573)\n"
     ]
    }
   ],
   "source": [
    "# import data into np array\n",
    "f = open(''.join([datadir, infilename, '.csv']))\n",
    "\n",
    "t1 = time.time()\n",
    "feature_names = f.readline()  # skip the header\n",
    "data = np.loadtxt(fname=f, delimiter=',')\n",
    "t2 = time.time()\n",
    "print(\"load data to np: %s sec\" % (t2 - t1))\n",
    "\n",
    "print(\"data shape:\",data.shape)\n",
    "\n",
    "# split into index, X and y\n",
    "t1 = time.time()\n",
    "index = data[:,0]\n",
    "y = data[:,-1]\n",
    "X = np.delete(data, [0, data.shape[1]-1], 1)\n",
    "t2 = time.time()\n",
    "print(\"split data: %s sec\" % (t2 - t1))\n",
    "del data\n",
    "\n",
    "print(\"X shape:\",X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features to use\n",
    "feature_names = feature_names.split(',')[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train:8000, #test:2000\n",
      "train: (8000, 573)\n",
      "test: (2000, 573)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "(num_rows, num_col) = X.shape\n",
    "num_train = math.ceil(num_rows * train_ratio)\n",
    "num_test = num_rows - num_train\n",
    "print(\"#train:%d, #test:%d\" % (num_train, num_test))\n",
    "\n",
    "train = X[:num_train,:]\n",
    "test = X[num_train:,:]\n",
    "del X\n",
    "print(\"train:\",train.shape)\n",
    "print(\"test:\",test.shape)\n",
    "\n",
    "# label\n",
    "y_train = y[:num_train]\n",
    "y_test = y[num_train:]\n",
    "\n",
    "# index\n",
    "index_train = index[:num_train]\n",
    "index_test = index[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(train)\n",
    "# scaling the features\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit the model: 0.3273911476135254 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf_perc = Perceptron(penalty=None, alpha=0.01, n_iter=10, eta0=1.0, n_jobs=16)\n",
    "\n",
    "# fit perceptron\n",
    "t1 = time.time()\n",
    "clf_perc = clf_perc.fit(train_scaled, y_train)\n",
    "t2 = time.time()\n",
    "print(\"fit the model: %s sec\" % (t2 - t1))\n",
    "\n",
    "# scoring\n",
    "yhat_perc_prob_test = clf_perc.predict(test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with ELNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alpha = 0.1\n",
    "l1_ratio = 0.05\n",
    "clf_enet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "# fit LR-elnet\n",
    "t1 = time.time()\n",
    "clf_enet = clf_enet.fit(train_scaled, y_train)\n",
    "t2 = time.time()\n",
    "print(\"fit the model: %s sec\" % (t2 - t1))\n",
    "\n",
    "# scoring\n",
    "yhat_elnet_prob_test = clf_enet.predict(test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12902499,  0.13860737,  0.28105311, ...,  0.12937989,\n",
       "        0.2618391 ,  0.22486954])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_elnet_prob_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# construct a classifier object for random target\n",
    "clf_rf = RandomForestClassifier(n_estimators=1500, criterion='gini', max_depth=None, \n",
    "                             min_samples_split=2, min_samples_leaf=5, max_features='auto', \n",
    "                             max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=16, \n",
    "                             random_state=None, verbose=0, min_density=None, compute_importances=None)\n",
    "\n",
    "# fit RF model to the train data\n",
    "t1 = time.time()\n",
    "clf_rf = clf_rf.fit(train, y_train)\n",
    "t2 = time.time()\n",
    "print(\"fit the model: %s sec\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binary classification output\n",
    "#yhat_test = clf_rf.predict(test)\n",
    "#pd.crosstab(yhat_test, y_test, rownames=['predicted'], colnames=['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probability output [good, bad]\n",
    "t1 = time.time()\n",
    "yhat_rf_prob_test = clf_rf.predict_proba(test)\n",
    "t2 = time.time()\n",
    "print(\"prediction: %s sec\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adjust the threshold. \n",
    "# If you set threshold = 0.5, the result is the same as clf_rf.predict(validate)\n",
    "bad_threshold = 0.4\n",
    "yhat = (yhat_prob_test[:,1] >= bad_threshold) + 0\n",
    "pd.crosstab(yhat, y_test, rownames=['predicted'], colnames=['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the variable importance\n",
    "var_imp = {'var_name':feature_names, 'imp':clf_rf.feature_importances_.tolist()}\n",
    "RF_imp = pd.DataFrame(var_imp, columns=['var_name','imp'])\n",
    "RF_imp.sort(columns='imp',axis=0,ascending=False,inplace=True, kind='quicksort', na_position='last')\n",
    "\n",
    "# display the features\n",
    "#HTML(pd.DataFrame(RF_imp).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output the test score\n",
    "\n",
    "# for RF\n",
    "yhat = yhat_rf_prob_test[:,1]\n",
    "y_true = y_test\n",
    "\n",
    "# for LR\n",
    "#yhat = yhat_elnet_prob_test\n",
    "#y_true = y_test\n",
    "\n",
    "# for perceptron\n",
    "#yhat = yhat_perc_prob_test\n",
    "#y_true = y_test\n",
    "\n",
    "# write to csv file\n",
    "output_file = pd.DataFrame({'score': yhat, 'tag': y_true})\n",
    "saved_filename = ''.join([datadir,infilename,'_',exp_id,'_predicted.csv'])\n",
    "output_file.to_csv(path_or_buf=saved_filename, sep=',', na_rep='', header=True, index=False)\n",
    "\n",
    "#python auccalc.py -f out_test.csv -t 1 -s 0 -l 0.0 -h 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "clf2save = clf_rf\n",
    "#clf2save = clf_enet\n",
    "#clf2save = clf_perc\n",
    "\n",
    "saved_filename = ''.join([datadir,infilename,'_',exp_id,'.pck'])\n",
    "fo = open(saved_filename, \"wb\")\n",
    "pickle.dump(clf2save, fo)\n",
    "fo.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "fo = open(saved_filename, \"rb\")\n",
    "clf_rf = pickle.load(fo)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the feature to text file\n",
    "saved_filename = ''.join([datadir,infilename,'_',exp_id,'_features.csv'])\n",
    "RF_imp.to_csv(path_or_buf=saved_filename, sep=',', na_rep='', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We should try:\n",
    "# gredient boosted tree\n",
    "# standardize the features\n",
    "# z-score the features\n",
    "# outlier detection\n",
    "# GLM\n",
    "# clustering (k-mean, RF) the transaction and model for each cluster\n",
    "# NN\n",
    "# semi-supervise learning\n",
    "# kernel method + SVM\n",
    "# Decision tree\n",
    "# multi-stage model\n",
    "# L1 + L2 norm LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gredient boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit classifier with out-of-bag estimates\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 3,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 5}\n",
    "clf_gbc = GradientBoostingClassifier(**params)\n",
    "\n",
    "t1 = time.time()\n",
    "clf_gbc.fit(train, y_train)\n",
    "t2 = time.time()\n",
    "print(\"GBC training: %s sec\" % (t2 - t1))\n",
    "\n",
    "yhat_test_gbc = clf_gbc.score(test, y_test)\n",
    "print(yhat_test_gbc)\n",
    "\n",
    "\n",
    "# Probability output [good, bad]\n",
    "t1 = time.time()\n",
    "yhat_gbc_prob_test = clf_gbc.predict_proba(test)\n",
    "#yhat_prob_test\n",
    "t2 = time.time()\n",
    "print(\"prediction: %s sec\" % (t2 - t1))\n",
    "\n",
    "# output the test score\n",
    "output_file = pd.DataFrame({'score': yhat_gbc_prob_test[:,1], 'tag': y_test})\n",
    "saved_filename = ''.join([datadir,infilename,'_',exp_id,'_predicted.csv'])\n",
    "output_file.to_csv(path_or_buf=saved_filename, sep=',', na_rep='', header=True, index=False)\n",
    "\n",
    "#python auccalc.py -f out_test.csv -t 1 -s 0 -l 0.0 -h 0.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "saved_filename = ''.join([datadir,infilename,'_',exp_id,'.pck'])\n",
    "fo = open(saved_filename, \"wb\")\n",
    "pickle.dump(clf_gbc, fo)\n",
    "fo.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/3 with method: k-means++\n",
      "Inertia for init 1/3: 141781.785408\n",
      "Init 2/3 with method: k-means++\n",
      "Inertia for init 2/3: 132158.614551\n",
      "Init 3/3 with method: k-means++\n",
      "Inertia for init 3/3: 139391.598526\n",
      "Minibatch iteration 1/8000: mean batch inertia: 425.629526, ewa inertia: 425.629526 \n",
      "Minibatch iteration 2/8000: mean batch inertia: 469.522060, ewa inertia: 426.726702 \n",
      "Minibatch iteration 3/8000: mean batch inertia: 539.011016, ewa inertia: 429.533459 \n",
      "Minibatch iteration 4/8000: mean batch inertia: 540.932714, ewa inertia: 432.318092 \n",
      "Minibatch iteration 5/8000: mean batch inertia: 595.819332, ewa inertia: 436.405112 \n",
      "Minibatch iteration 6/8000: mean batch inertia: 502.485069, ewa inertia: 438.056905 \n",
      "Minibatch iteration 7/8000: mean batch inertia: 687.512932, ewa inertia: 444.292526 \n",
      "Minibatch iteration 8/8000: mean batch inertia: 458.289061, ewa inertia: 444.642396 \n",
      "Minibatch iteration 9/8000: mean batch inertia: 439.888503, ewa inertia: 444.523563 \n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "Minibatch iteration 10/8000: mean batch inertia: 382.996479, ewa inertia: 442.985578 \n",
      "Minibatch iteration 11/8000: mean batch inertia: 599.641856, ewa inertia: 446.901496 \n",
      "Converged (lack of improvement in inertia) at iteration 11/8000\n",
      "Computing label assignment and total inertia\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# k-mean\n",
    "clf_mbk = MiniBatchKMeans(n_clusters=10, init='k-means++', max_iter=100, batch_size=100, verbose=True)\n",
    "clf_mbk = clf_mbk.fit(train_scaled)\n",
    "\n",
    "# size of each cluster\n",
    "mbk_train = pd.DataFrame({'label':clf_mbk.labels_ })\n",
    "mbk_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 15 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 7997, 7998, 7999])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Affinity Propagation\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "clf_af = AffinityPropagation(preference=-50, damping=0.5, max_iter=200, convergence_iter=15, verbose=True)\n",
    "clf_af = clf_af.fit(train_scaled)\n",
    "clf_af.cluster_centers_indices_\n",
    "clf_af.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we want to know a few things:\n",
    "# 1) How many unique values\n",
    "# 2) correlation corr(x,y)\n",
    "# 3) mutual information MI(x,y)\n",
    "# 4) distribution of bad/good in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_info(x, name):\n",
    "    \n",
    "    # number of unique value\n",
    "    unique_x = np.unique(x)\n",
    "    num_unique = len(unique_x)\n",
    "    \n",
    "    # Pearson correlation coefficient\n",
    "    pcorr = np.corrcoef(x, y_train)[0,1]\n",
    "    \n",
    "    import sklearn.metrics\n",
    "    mi = sklearn.metrics.mutual_info_score(y_train, x)\n",
    "\n",
    "    var_info = pd.DataFrame({'name':[name],\n",
    "                             'num_unique':[num_unique],\n",
    "                             'pcorr':[pcorr],\n",
    "                             'mi':[mi]})\n",
    "    var_info = var_info[['name', 'num_unique', 'pcorr', 'mi']]\n",
    "    return var_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate variables info\n",
    "var_info = pd.DataFrame({'name':[],\n",
    "                             'num_unique':[],\n",
    "                             'pcorr':[],\n",
    "                             'mi':[]})\n",
    "for i in range(train.shape[1]):\n",
    "    var_info = pd.concat(objs=[var_info, variable_info(train[:,i],\"v%d\" % (i+1))], axis=0)\n",
    "    \n",
    "var_info = var_info[['name', 'num_unique', 'pcorr', 'mi']] \n",
    "\n",
    "# set var name as index\n",
    "var_info.set_index(keys='name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load RF feature important\n",
    "infilename = 'hackathon2015_train_800k_tree500_split2_leaf5_features'\n",
    "tp = pd.read_csv(filepath_or_buffer=''.join([datadir, infilename, '.csv']),\n",
    "                     sep=',', na_values=['.', ''],\n",
    "                     header=0, iterator=True, chunksize=1000)\n",
    "rf_car_imp = pd.concat(list(tp), ignore_index=True)\n",
    "# set var name as index\n",
    "rf_car_imp.set_index(keys='var_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine all the information\n",
    "var_info = pd.concat(objs=[var_info, rf_car_imp], axis=1)\n",
    "var_info.sort(columns=['imp', 'mi', 'pcorr'], ascending=False, inplace=True)\n",
    "var_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output the feature information\n",
    "var_info.to_csv(path_or_buf='variable_info.csv', sep=',', na_rep='', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>P1</th>\n",
       "      <th>P0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2.909570</th>\n",
       "      <td>    4</td>\n",
       "      <td>    3</td>\n",
       "      <td> 0.428571</td>\n",
       "      <td> 0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909552</th>\n",
       "      <td>    3</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909534</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909517</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909499</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909481</th>\n",
       "      <td>    4</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909446</th>\n",
       "      <td>    2</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909411</th>\n",
       "      <td>    4</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909393</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909358</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909340</th>\n",
       "      <td>    2</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909252</th>\n",
       "      <td>    5</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.909006</th>\n",
       "      <td>    2</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908935</th>\n",
       "      <td>    5</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908865</th>\n",
       "      <td>   27</td>\n",
       "      <td>    1</td>\n",
       "      <td> 0.035714</td>\n",
       "      <td> 0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908794</th>\n",
       "      <td>    0</td>\n",
       "      <td>    1</td>\n",
       "      <td> 1.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908776</th>\n",
       "      <td>    2</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908583</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908389</th>\n",
       "      <td>    1</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908283</th>\n",
       "      <td>    3</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.908177</th>\n",
       "      <td>    2</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.907437</th>\n",
       "      <td>    4</td>\n",
       "      <td>    1</td>\n",
       "      <td> 0.200000</td>\n",
       "      <td> 0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.907314</th>\n",
       "      <td>    8</td>\n",
       "      <td>    2</td>\n",
       "      <td> 0.200000</td>\n",
       "      <td> 0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.906591</th>\n",
       "      <td>   20</td>\n",
       "      <td>    1</td>\n",
       "      <td> 0.047619</td>\n",
       "      <td> 0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.905551</th>\n",
       "      <td>    3</td>\n",
       "      <td>    1</td>\n",
       "      <td> 0.250000</td>\n",
       "      <td> 0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.903471</th>\n",
       "      <td>    8</td>\n",
       "      <td>    3</td>\n",
       "      <td> 0.272727</td>\n",
       "      <td> 0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.901568</th>\n",
       "      <td>   14</td>\n",
       "      <td>    2</td>\n",
       "      <td> 0.125000</td>\n",
       "      <td> 0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.900598</th>\n",
       "      <td>   40</td>\n",
       "      <td>    7</td>\n",
       "      <td> 0.148936</td>\n",
       "      <td> 0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.900193</th>\n",
       "      <td>   26</td>\n",
       "      <td>    3</td>\n",
       "      <td> 0.103448</td>\n",
       "      <td> 0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.895945</th>\n",
       "      <td>    1</td>\n",
       "      <td>    7</td>\n",
       "      <td> 0.875000</td>\n",
       "      <td> 0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.895874</th>\n",
       "      <td>   25</td>\n",
       "      <td>    4</td>\n",
       "      <td> 0.137931</td>\n",
       "      <td> 0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.887255</th>\n",
       "      <td>  112</td>\n",
       "      <td>    8</td>\n",
       "      <td> 0.066667</td>\n",
       "      <td> 0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.777888</th>\n",
       "      <td>  462</td>\n",
       "      <td>   49</td>\n",
       "      <td> 0.095890</td>\n",
       "      <td> 0.904110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th> 0.351947</th>\n",
       "      <td> 5779</td>\n",
       "      <td> 1298</td>\n",
       "      <td> 0.183411</td>\n",
       "      <td> 0.816589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th> 0.613107</th>\n",
       "      <td>   35</td>\n",
       "      <td>    0</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y             0     1        P1        P0\n",
       "x                                        \n",
       "-2.909570     4     3  0.428571  0.571429\n",
       "-2.909552     3     0  0.000000  1.000000\n",
       "-2.909534     1     0  0.000000  1.000000\n",
       "-2.909517     1     0  0.000000  1.000000\n",
       "-2.909499     1     0  0.000000  1.000000\n",
       "-2.909481     4     0  0.000000  1.000000\n",
       "-2.909446     2     0  0.000000  1.000000\n",
       "-2.909411     4     0  0.000000  1.000000\n",
       "-2.909393     1     0  0.000000  1.000000\n",
       "-2.909358     1     0  0.000000  1.000000\n",
       "-2.909340     2     0  0.000000  1.000000\n",
       "-2.909252     5     0  0.000000  1.000000\n",
       "-2.909006     2     0  0.000000  1.000000\n",
       "-2.908935     5     0  0.000000  1.000000\n",
       "-2.908865    27     1  0.035714  0.964286\n",
       "-2.908794     0     1  1.000000  0.000000\n",
       "-2.908776     2     0  0.000000  1.000000\n",
       "-2.908583     1     0  0.000000  1.000000\n",
       "-2.908389     1     0  0.000000  1.000000\n",
       "-2.908283     3     0  0.000000  1.000000\n",
       "-2.908177     2     0  0.000000  1.000000\n",
       "-2.907437     4     1  0.200000  0.800000\n",
       "-2.907314     8     2  0.200000  0.800000\n",
       "-2.906591    20     1  0.047619  0.952381\n",
       "-2.905551     3     1  0.250000  0.750000\n",
       "-2.903471     8     3  0.272727  0.727273\n",
       "-2.901568    14     2  0.125000  0.875000\n",
       "-2.900598    40     7  0.148936  0.851064\n",
       "-2.900193    26     3  0.103448  0.896552\n",
       "-2.895945     1     7  0.875000  0.125000\n",
       "-2.895874    25     4  0.137931  0.862069\n",
       "-2.887255   112     8  0.066667  0.933333\n",
       "-2.777888   462    49  0.095890  0.904110\n",
       " 0.351947  5779  1298  0.183411  0.816589\n",
       " 0.613107    35     0  0.000000  1.000000"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the variable binning\n",
    "x = train[:,83]\n",
    "dfxy = pd.DataFrame({'x':x, 'y':y_train.astype(int)})\n",
    "var_bin = pd.crosstab(index=dfxy.x, columns=[dfxy.y])\n",
    "var_bin['P1'] = var_bin[1]/(var_bin[0]+var_bin[1])\n",
    "var_bin['P0'] = var_bin[0]/(var_bin[0]+var_bin[1])\n",
    "var_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>P1</th>\n",
       "      <th>P0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-10.567689</th>\n",
       "      <td>   26</td>\n",
       "      <td>   45</td>\n",
       "      <td> 0.633803</td>\n",
       "      <td> 0.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th> 0.094628 </th>\n",
       "      <td> 6583</td>\n",
       "      <td> 1346</td>\n",
       "      <td> 0.169757</td>\n",
       "      <td> 0.830243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y              0     1        P1        P0\n",
       "x                                         \n",
       "-10.567689    26    45  0.633803  0.366197\n",
       " 0.094628   6583  1346  0.169757  0.830243"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
